{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMTransformerEncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, macro_dim, embed_dim, lstm_hidden_dim, lstm_layers, num_heads, num_layers, dropout=0.1, output_seq_len=1):\n",
    "        super(LSTMTransformerEncoderDecoder, self).__init__()\n",
    "        \n",
    "        # LSTM Encoder for past sequence data\n",
    "        self.lstm_encoder = nn.LSTM(input_dim, lstm_hidden_dim, lstm_layers, batch_first=True)\n",
    "        \n",
    "        # Linear layer to embed LSTM output to Transformer-compatible dimension\n",
    "        self.past_embedding = nn.Linear(lstm_hidden_dim, embed_dim)\n",
    "        \n",
    "        # Macro data embedding\n",
    "        self.macro_embedding = nn.Linear(macro_dim, embed_dim)\n",
    "        \n",
    "        # Positional encoding for the past sequence\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, embed_dim))  # Assuming max sequence length of 1000\n",
    "        \n",
    "        # Transformer Encoder layers\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # LSTM Decoder\n",
    "        self.lstm_decoder = nn.LSTM(embed_dim, lstm_hidden_dim, lstm_layers, batch_first=True)\n",
    "        \n",
    "        # Linear output layer\n",
    "        self.output_layer = nn.Linear(lstm_hidden_dim, input_dim)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output sequence length for forecasting multiple steps\n",
    "        self.output_seq_len = output_seq_len\n",
    "        \n",
    "    def forward(self, past_sequence, macro_today):\n",
    "        \"\"\"\n",
    "        past_sequence: (batch_size, sequence_length, input_dim) - historical sequence data\n",
    "        macro_today: (batch_size, macro_dim) - today's macro data\n",
    "        \"\"\"\n",
    "        \n",
    "        # LSTM Encoder: process the past sequence data\n",
    "        lstm_out, (h_n, c_n) = self.lstm_encoder(past_sequence)  # lstm_out: (batch_size, sequence_length, lstm_hidden_dim)\n",
    "        \n",
    "        # Embed the LSTM output to transformer-compatible dimension\n",
    "        past_embedded = self.past_embedding(lstm_out)  # (batch_size, sequence_length, embed_dim)\n",
    "        \n",
    "        # Add positional encodings to past sequence\n",
    "        seq_length = past_embedded.size(1)\n",
    "        past_embedded = past_embedded + self.positional_encoding[:, :seq_length, :]\n",
    "        \n",
    "        # Embed todayâ€™s macro data and expand for broadcasting\n",
    "        macro_today_embedded = self.macro_embedding(macro_today)  # (batch_size, embed_dim)\n",
    "        macro_today_embedded = macro_today_embedded.unsqueeze(1)  # (batch_size, 1, embed_dim)\n",
    "        \n",
    "        # Concatenate past and macro embeddings to allow today's data to influence predictions\n",
    "        x = torch.cat([past_embedded, macro_today_embedded], dim=1)  # (batch_size, sequence_length + 1, embed_dim)\n",
    "        \n",
    "        # Transpose for transformer input (sequence_length + 1, batch_size, embed_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Transpose back to (batch_size, sequence_length + 1, embed_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # LSTM Decoder for autoregressive prediction\n",
    "        decoder_input = x[:, -1, :].unsqueeze(1)  # Start with the output of the last transformer step\n",
    "        \n",
    "        # Collect decoder outputs\n",
    "        decoder_outputs = []\n",
    "        hidden_state, cell_state = h_n, c_n  # Initialize with the encoder LSTM's final hidden states\n",
    "        \n",
    "        for _ in range(self.output_seq_len):\n",
    "            # Pass through LSTM Decoder one step at a time\n",
    "            decoder_output, (hidden_state, cell_state) = self.lstm_decoder(decoder_input, (hidden_state, cell_state))\n",
    "            \n",
    "            # Apply output layer to get the forecast for this step\n",
    "            step_output = self.output_layer(decoder_output.squeeze(1))  # (batch_size, input_dim)\n",
    "            decoder_outputs.append(step_output)\n",
    "            \n",
    "            # Prepare next input (autoregressive)\n",
    "            decoder_input = decoder_output  # Feed the last output as the next input\n",
    "            \n",
    "        # Stack all the step outputs\n",
    "        final_output = torch.stack(decoder_outputs, dim=1)  # (batch_size, output_seq_len, input_dim)\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "# Model configuration\n",
    "input_dim = 5                # Number of input features\n",
    "macro_dim = 3                # Number of macroeconomic variables\n",
    "embed_dim = 64               # Embedding dimension for Transformer\n",
    "lstm_hidden_dim = 128        # Hidden dimension for LSTM\n",
    "lstm_layers = 2              # Number of LSTM layers\n",
    "num_heads = 4                # Number of attention heads in Transformer\n",
    "num_layers = 2               # Number of Transformer layers\n",
    "dropout = 0.1                # Dropout rate\n",
    "output_seq_len = 5           # Number of forecasted steps\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMTransformerEncoderDecoder(input_dim, macro_dim, embed_dim, lstm_hidden_dim, lstm_layers, num_heads, num_layers, dropout, output_seq_len)\n",
    "\n",
    "# Example input (batch_size=32, sequence_length=10, input_dim=5)\n",
    "past_sequence = torch.randn(32, 10, input_dim)  # Historical sequence data\n",
    "macro_today = torch.randn(32, macro_dim)        # Today's macroeconomic data\n",
    "\n",
    "# Get the output prediction\n",
    "output = model(past_sequence, macro_today)\n",
    "print(output.shape)  # Expected: (32, output_seq_len, input_dim)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
